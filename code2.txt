from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import IntegerType
import numpy as np
import joblib

# Create a Spark session
spark = SparkSession.builder.appName("ScikitToPyspark").getOrCreate()

# Path to the saved scikit-learn model
scikit_model_path = 'path_to_saved_model.pkl'

# Load scikit-learn model
scikit_rf_model = joblib.load(scikit_model_path)

# Load your data into a PySpark DataFrame (assuming you have a DataFrame named 'data')
# Replace with your data loading approach
# data = spark.read.csv('path_to_your_data.csv', header=True, inferSchema=True)

# Define the feature columns
feature_columns = ['col1', 'col2', 'col3', 'col4']  # Replace with your feature column names

# Function to predict using scikit-learn model
def predict(values):
    return scikit_rf_model.predict(np.array(values).reshape(1, -1))[0]

# Create a UDF for prediction
predict_udf = udf(predict, IntegerType())

# Apply predictions using the UDF
result_df = data.withColumn("prediction", predict_udf(*feature_columns))

# Show or further process the result_df DataFrame
result_df.show()

# Stop the Spark session when finished
spark.stop()
