from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql.functions import col, when

# Create SparkSession
spark = SparkSession.builder \
    .appName("ModifySubsetMultipleColumns") \
    .getOrCreate()

# Sample data
data = [
    Row(id=1, name="John", age=28, salary=3000.0, bonus=500.0),
    Row(id=2, name="Jane", age=35, salary=4000.0, bonus=600.0),
    Row(id=3, name="Bill", age=45, salary=5000.0, bonus=700.0),
    Row(id=4, name="Anna", age=23, salary=3500.0, bonus=550.0)
]

# Create DataFrame
df = spark.createDataFrame(data)
df.show()

# Apply conditional transformations to the 'salary' and 'bonus' columns
modified_df = df.withColumn(
    "salary",
    when(col("age") > 40, col("salary") * 1.10)
    .when((col("age") > 30) & (col("age") <= 40), col("salary") * 1.05)
    .otherwise(col("salary"))
).withColumn(
    "bonus",
    when(col("age") > 40, col("bonus") * 1.05)
    .when((col("age") > 30) & (col("age") <= 40), col("bonus") * 1.02)
    .otherwise(col("bonus"))
)

# Show the modified DataFrame
modified_df.show()

# Stop SparkSession
spark.stop()